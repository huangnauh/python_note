多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。

多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。

多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。

在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。

计算密集型任务同时进行的数量应当等于CPU的核心数。计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。

Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。

第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。

Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。

服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务：

	# taskmanager.py
	
	import random, time, Queue
	from multiprocessing.managers import BaseManager
	
	# 发送任务的队列:
	task_queue = Queue.Queue()
	# 接收结果的队列:
	result_queue = Queue.Queue()
	
	# 从BaseManager继承的QueueManager:
	class QueueManager(BaseManager):
	    pass
	
	# 把两个Queue都注册到网络上, callable参数关联了Queue对象:
	QueueManager.register('get_task_queue', callable=lambda: task_queue)
	QueueManager.register('get_result_queue', callable=lambda: result_queue)
	# 绑定端口5000, 设置验证码'abc':
	manager = QueueManager(address=('', 5000), authkey='abc')
	# 启动Queue:
	manager.start()
	# 获得通过网络访问的Queue对象:
	task = manager.get_task_queue()
	result = manager.get_result_queue()
	# 放几个任务进去:
	for i in range(10):
	    n = random.randint(0, 10000)
	    print('Put task %d...' % n)
	    task.put(n)
	# 从result队列读取结果:
	print('Try get results...')
	for i in range(10):
	    r = result.get(timeout=10)
	    print('Result: %s' % r)
	# 关闭:
	manager.shutdown()


在另一台机器上启动任务进程:

	# taskworker.py
	
	import time, sys, Queue
	from multiprocessing.managers import BaseManager
	
	# 创建类似的QueueManager:
	class QueueManager(BaseManager):
	    pass
	
	# 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字:
	QueueManager.register('get_task_queue')
	QueueManager.register('get_result_queue')
	
	# 连接到服务器，也就是运行taskmanager.py的机器:
	server_addr = '127.0.0.1'
	print('Connect to server %s...' % server_addr)
	# 端口和验证码注意保持与taskmanager.py设置的完全一致:
	m = QueueManager(address=(server_addr, 5000), authkey='abc')
	# 从网络连接:
	m.connect()
	# 获取Queue的对象:
	task = m.get_task_queue()
	result = m.get_result_queue()
	# 从task队列取任务,并把结果写入result队列:
	for i in range(10):
	    try:
	        n = task.get(timeout=1)
	        print('run task %d * %d...' % (n, n))
	        r = '%d * %d = %d' % (n, n, n*n)
	        time.sleep(1)
	        result.put(r)
	    except Queue.Empty:
	        print('task queue is empty.')
	# 处理结束:
	print('worker exit.')



multiprocessing提供的进程间通信默认不是协作式的。由于基于 multiprocessing.Connection的对象(例如Pipe)暴露了它们下面的 文件描述符(file descriptor)，gevent.socket.wait_read和wait_write 可以用来在直接读写之前协作式的`等待ready-to-read/ready-to-write事件`。

	import gevent
	from multiprocessing import Process, Pipe
	from gevent.socket import wait_read, wait_write
	
	a, b = Pipe()
	
	c, d = Pipe()
	
	def relay():
	    for i in xrange(10):
	        msg = b.recv()
	        c.send(msg + " in " + str(i))
	
	def put_msg():
	    for i in xrange(10):
	        wait_write(a.fileno())
	        a.send('hi')
	
	def get_msg():
	    for i in xrange(10):
	        wait_read(d.fileno())
	        print(d.recv())
	
	if __name__ == '__main__':
	    proc = Process(target=relay)
	    proc.start()
	
	    g1 = gevent.spawn(get_msg)
	    g2 = gevent.spawn(put_msg)
	    gevent.joinall([g1, g2], timeout=1)


在兼容POSIX的系统创建子进程(forking)之后， 在子进程的gevent的状态是不适定的(ill-posed)。一个副作用就是， multiprocessing.Process创建之前的greenlet创建动作，会在父进程和子进程两方都运行。

上例的put_msg()中的a.send()可能`依然非协作式地阻塞`调用的线程：一个 ready-to-write事件`只保证写了一个byte`。在`尝试写完成之前底下的buffer可能是满的`。

上面表示的基于wait_write()/wait_read()的方法在Windows上不工作 (IOError: 3 is not a socket (files are not supported))，因为`Windows不能监视 pipe事件`。

Python包gipc以大体上透明的方式在 兼容POSIX系统和Windows上克服了这些挑战。它提供了gevent感知的基于 multiprocessing.Process的子进程和gevent基于pipe的协作式进程间通信。



####流式HTTP服务(streaming HTTP service)

它的核心思想 就是在头部(header)不指定内容的长度
('Transfer-Encoding', 'chunked')
分块传输编码（Chunked transfer encoding）是超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由网页服务器发送给客户端应用（ 通常是网页浏览器）的数据可以分成多个部分。分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供
HTTP 1.1引入分块传输编码提供了以下几点好处：
1.	HTTP分块传输编码允许服务器`为动态生成的内容维持HTTP持久链接`。通常，持久链接需要服务器在开始发送消息体前发送Content-Length消息头字段，但是对于动态生成的内容来说，在内容创建完之前是不可知的
2.	`分块传输编码允许服务器在最后发送消息头字段`。对于那些头字段值在内容被生成之前无法知道的情形非常重要，例如消息的内容要使用散列进行签名，散列的结果通过HTTP消息头字段进行传输。没有分块传输编码时，服务器必须缓冲内容直到完成后计算头字段的值并在发送内容前发送这些头字段的值。
3.	HTTP服务器有时使用压缩 （gzip或deflate）以缩短传输花费的时间。分块传输编码可以用来分隔压缩对象的多个部分。在这种情况下，块不是分别压缩的，而是整个负载进行压缩，压缩的输出使用本文描述的方案进行分块传输。在压缩的情形中，分块编码有利于一边进行压缩一边发送数据，而不是先完成压缩过程以得知压缩后数据的大小。

格式:
如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，`消息体由数量未定的块组成，并以最后一个大小为0的块为结束。`

`每一个非空的块都以该块包含数据的字节数`（字节数以十六进制表示）开始，`跟随一个CRLF` （回车及换行），然后是`数据本身`，最后块`CRLF结束`。在一些实现中，`块大小和CRLF之间填充有白空格（0x20）`。

`最后一块是单行，由块大小（0），一些可选的填充白空格，以及CRLF`。最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段。

消息最后以CRLF结尾。


基于HTTP的长连接,是一种通过长轮询方式实现"服务器推"的技术

轮询：客户端定时向服务器发送Ajax请求，服务器接到请求后马上返回响应信息并关闭连接。 

长轮询：客户端向服务器发送Ajax请求，服务器接到请求后hold住连接，直到有新消息才返回响应信息并关闭连接，客户端处理完响应信息后再向服务器发送新的请求。 

长连接：在页面里嵌入一个隐蔵iframe，将这个隐蔵iframe的src属性设为对一个长连接的请求或是采用xhr请求，服务器端就能源源不断地往客户端输入数据。 

Flash Socket：在页面中内嵌入一个使用了Socket类的 Flash 程序JavaScript通过调用此Flash程序提供的Socket接口与服务器端的Socket接口进行通信，JavaScript在收到服务器端传送的信息后控制页面的显示。 

1.轮询的建立 
建立轮询的过程很简单，浏览器发起请求后进入循环等待状态，此时由于服务器还未做出应答，所以HTTP也一直处于连接状态中。 

2.数据的推送 
在循环过程中，服务器程序对数据变动进行监控，如发现更新，将该信息输出给浏览器，随即断开连接，完成应答过程，实现“服务器推”。 

3.轮询的终止 
轮询可能在以下3种情况时终止：
 
3.1. 有新数据推送 
当循环过程中服务器向浏览器推送信息后，应该主动结束程序运行从而让连接断开，这样浏览器才能及时收到数据。 

3.2. 没有新数据推送
循环不能一直持续下去，应该设定一个最长时限，避免WEB服务器超时（Timeout），若一直没有新信息，服务器应主动向浏览器发送本次轮询无新信息的正常响应，并断开连接，这也被称为“心跳”信息。
 
3.3. 网络故障或异常 
由于网络故障等因素造成的请求超时或出错也可能导致轮询的意外中断，此时浏览器将收到错误信息。 

4.轮询的重建 
浏览器收到回复并进行相应处理后，应马上重新发起请求，开始一个新的轮询周期。


###持久连接
现有的持久连接类型有两种：HTTP/1.0+的keep-alive和HTTP/1.1的persistent.

####HTTP/1.0+的keep-alive:

客户端先发出请求,以connection：keep-alive的形式传向服务器,如果服务器接受的请求的话响应中就会带有connection：keep-alive.

当使用了connection：keep-alive时，可以使用keep-alive首部传递一些关于持久连接的参数：`timeout表示持续时间`，`max表示希望还在这条持久连接上传输多少个HTTP服务`，但是这些都`不是承诺值`，也就是说随时都可以反悔。

接下来说说keep-alive持久连接需要注意的一些地方：

如果要是用持久连接，那么就`一定要有正确的content-length这个描述主体长度的首部`，因为持久连接会连续的传输HTTP事务，而判断连续的HTTP事务之间的分界点就是靠content-length告诉的主体的长度了，如果错误或没有告诉主体的长度的话，那么就没办法知道这个事务在哪里结束了。
代理和网管必须`再转发之前删除`connection：keep-alive这个首部，这个涉及到`哑代理`问题。
因为持久连接可以随时关闭，所以一定要做好遇到当请求发出去响应还没回送回来的时候持久连接就断开的情况的准备，也就是有些时候可能要从新发送请求。

这里先说明下哑代理和聪明的代理的区别：`哑代理只是单纯的转发请求`，并`不能进行解析处理、维持持久连接`等其他工作，而聪明的代理可以解析接收到的报文同时可以维持持久连接。
哑代理只有一种行为模式：在转发请求和回送服务器响应请求之后就认为这次事务结束了，等待连接断开
所以为了避免这种情况，现代的代理是不会转发connection：keep-alive这个首部的。
为了防止这个问题，采用插入Proxy-connection的方式


首先客户端发送`Proxy-connection`首部请求，这是一个`非标准请求`，也就是说即使服务器接收到这个首部也不知道他是干什么的，在服务器眼中它只知道客户端申请持久连接的首部为connection：keep-alive

哑代理的模式：报文来到了代理的位置，哑代理的话会直接转发请求不解析处理，则Proxy-connection这个首部直接被发给服务器，由于服务器不识别，所以直接忽略到这个首部，这样服务器在返回响应的时候便不会带有connection：keep-alive首部，当响应到达客户端的时候，客户端发现响应中没有connection：keep-alive首部，就认为服务器拒绝了持久连接的请求，也就是说客户端判断服务器是否接受持久连接请求仍是靠响应是否存在connection首部来进行的。
聪明的代理的模式：聪明的代理会对请求进行解析，发现有 Proxy-connection这个首部的时候，便会把这个首部替换成connection：keep-alive，由于服务器只能识别connection首部，当它发现有这个首部的时候，就知道客户端进行了持久连接请求，就在响应中添加connection首部，回送给客户端。当客户端收到带有connection首部的响应时，便认为持久连接建立成功，而正好中间的聪明的路由也可以维持持久连接，这样整条连接就处于客户端OK代理OK服务器OK的状态，可以继续使用该持久连接进行报文发送。
从上面所说的，我觉得这个方案其实就是相当于对中间代理的类型进行了一次判断。
但是这个方案只能解决中间只有一个代理的情况，如果聪明的任意一边还存在一个哑代理，那么仍会出现最开始的哑代理问题。



####persistent
HTTP/1.1的持久连接默认是开启的，只有首部中包含connection：close，才会事务结束之后关闭连接。当然服务器和客户端仍可以随时关闭持久连接。


####代理
代理可以分为公有代理和私有代理
某些代理的功能如高速缓存，会利用用户的共同的请求，所以使用的用户越多，代理越高效。
私人代理一般很少见，我们可能接触到的例如浏览器自带的本地代理，用来提高性能，或者完成一些特定的功能。

为什么要使用代理
1.	`内容过滤`。
2.	`文件访问控制`
3.	`防火墙`。对网络流量进行监控
4.	`web缓存`。
5.	`反向代理`。代理可以假扮服务器，用户的请求会先发送到假扮服务器的反向代理上，然后反向代理根据一些判断规则将请求分发到特定服务器，或者直接将缓存中的数据返回。主要作用是性能优化和负载平衡等。
6.	`内容路由器`。可以用来实现各种服务级的请求，比如如果用户或内容提供者付费要求更高的性能，内容路由器便可以将请求转发到附近的复制缓存中。
7.	`转码器`。代理服务器在将内容发送给客户端之前，可以修改内容的格式，这种表示法之间进行的透明转换被称为转码。例如服务器返回的是GIF图片，转码代理可以讲其转换为JPEG格式，以此来减小尺寸。
8.	`匿名`。有些时候，我们不希望服务器获得我们客户端的信息，代理服务器可以再转发请求的时候将客户端的IP地址，From首部，Referer首部，cookie，URI会话的ID等从请求中去掉，从而实现匿名。


`缓存命中问题`
`再验证`:当一个请求到达缓存的时候，缓存有这个资源的副本，但是他不知道这个副本过没过期，自己又不能进行决定，所以就向服务器发送验证请求，检测这个资源的内容是不是最新的。缓存可以在任意时刻，以任意频率对副本进行验证，但是为了节省带宽，`基本上客户端发起请求的时候才会进行验证`。在进行在验证的时候，缓存会向服务器发送一个再验证请求，如果内容没有变化，服务器则会返回一个`304 NOT MODIFIED`的响应，这就说明这个副本是暂时新鲜的，就可以返回给客户端了。这就就叫做`再验证命中`或者`缓慢命中`。如果副本过期，那么服务器就直接返回一个响应报文，报头为 200 ok,这个响应报文会发回给客户端。如果服务器上已经删除了这个对象，那么服务器会返回一个`404 NOT FOUND响应`，缓存接收到这个响应，`也会删这个资源的副本`，同时将响应回送。

`If-Modified-Since`：如果从指定日期之后资源被修改过了，那么就返回新的资源，可以与`Last-Modified`首部配合使用。如果资源没有发生变化的话，服务器就会回送一个304 NOT Modified响应。

`If-None-Match`：服务器可以为每一个资源定义一个特定的标签，如果说进行再验证的副本资源的标签与当前服务器上的标签不同，则返回新的资源。
有些文档可能会进行周期性的重写，但实际上并没有发生变化。所以需要`If-None-Match`及`ETag` 


客户端如何判断一个资源是否从缓存中来的呢？基本上有两种方法，一种是有的缓存在返回资源时候，会在回送响应中添加`VIA首部`，表示这是从缓存中返回的。第二种方法使查看返回响应报文的`DATE首部`，如果这个首部比起现在的时间早很多，那么很有可能这个资源就是由缓存中返回的。（`DATE首部记录的是该响应于服务器产生的时间`。）


`资源过期`

通过 Cache-Control首部和expires首部，原始服务器可以对资源定义其保质期。在保质期之内，缓存就认为该资源是新鲜的，可以直接传回给客户端，如果过期那么就需要进行再验证。
`Cache-Control`使用的是相对时间，而`expires`使用的是绝对时间，绝对时间依赖于计算机时钟，所以建议使用Cache-Control首部

Cache-Control:max-age=484200

服务器可以通过http定义的几种header对可以缓存数据的存在时间进行控制，按照其优先级由高到低分别为：

Cache-Control：no-store
Cache-Control：no-cache
Cache-Control：must-revalidata
Cache-Control:  max-age=
Expires:{date}






####TCP滑动窗口
TCP必需要解决的可靠传输以及包乱序（reordering）的问题，所以，TCP必需要知道网络实际的数据处理带宽或是数据处理速度，这样才不会引起网络拥塞，导致丢包。

TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 

Zero Window一个处理缓慢的Server（接收端）是怎么把Client（发送端）的TCP Sliding Window给降成0的。

TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。

####TCP的拥塞处理 - Congestion Handling
TCP通过Sliding Window来做流控（Flow Control）
因为Sliding Window需要依赖于连接的发送端和接收端，其并不知道网络中间发生了什么
因为流控只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。

#####TCP慢启动

TCP数据传输性能还取决于`TCP连接的使用期`。TCP连接会随着`时间自我调整`。`起初会限制最大速度`，如果`数据传输成功`，那么就会`随着时间提高传输速度`，这就被称为`TCP慢启动`，目的是为了防止互联网的突然过载。

慢启动限制了TCP端点在任意时刻的可以传输数据的分组数，例如，每成功接收一个分组，发送端就有了发送另两个分组的权限，如果要发送大量数据，是不能一次性将所有分组都发出去的，必须发送一个分组，等待确认，然后可以发送两个分组，每个都确认，然后可以发送四个，以此类推，这个方式叫做`打开拥塞窗口`。所以，`新连接会比已经使用过一段时间的连接慢一些`，为了保存这些使用过一段时间的连接，可以使用`持久连接`的方式。

慢启动的算法如下(cwnd全称Congestion Window)：
1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。
(MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，这是因为 RFC 791里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，而576减去IP头的20个字节就是536）。)

2）每当收到一个ACK，cwnd++; 呈线性上升

3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升

4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）

#####拥塞避免算法
当丢包的时候，会有两种情况：

1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。
sshthresh =  cwnd /2
cwnd 重置为 1
进入慢启动过程

2）Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。
TCP Tahoe的实现和RTO超时一样。
TCP Reno的实现是：
cwnd = cwnd /2
sshthresh = cwnd
进入快速恢复算法——Fast Recovery

3) 快速恢复算法 – Fast Recovery



####延迟确认
由于在网络超负荷的情况下，`路由器可以随意丢弃分组`，所以TCP需要确保传输的正确性。每个TCP段都有个序列号和数据完整性校验和。每个段的接受者接收到完整的段时，都会向发送者`回送一个确认分组`，告知发送端已经发送成功，如果发送端`没有在一定时间内接收到确认分组`，那么就会认为发送失败，`会从新发送该段数据`。

由于确认报文都很小，所以TCP允许在发往同一方向的输出数据分组中捎带它，这可以更有效利用网络带宽。为了提高这种捎带的几率，很多TCP栈都实现了一种`延迟确认`方法，他会在一个`特定的时间内`（通常100~200毫秒）内将输出确认存放到缓存中，`等待可以捎带他的数据`，如果在时间诶没有数据，那么就独立传输。所以HTTP具有`双峰特征的请求应答行为`降低了捎带信息的可能性，所以捎带的确认信息往往会等待一段时间后，独立发送，这无疑浪费了很多时间，当HTTP请求是这种情况时候，可以考虑关闭延迟确认。


####数据聚集的Nagle算法
应用程序可以通过数据流接口将`任意尺寸的数据放入TCP栈中`，即使一次只有一字节也可以，但是每个TCP段都至少装载了`40个字节的标记和首部`，为了发送1字节浪费了40字节，这显然会造成网络性能的下降。

Nagle算法为了提高效率，试图将大量TCP数据捆绑在一起。该算法鼓励发送全尺寸（LAN最大尺寸是1500字节，因特网上市几百字节）的段，只有所有其他分组被确认之后，判断等不到继续打包的数据，就发送非全尺寸的段，如果仍有其他分组在传送过程中，就将那部分数据缓存起来，等待有其他数据可以捆绑起来一起发出。

####TIME_WAIT时延和端口耗尽

因为TCP连接是双向的，所以在关闭连接的时候，两个方向各自都需要关闭。先发FIN包的一方执行的是主动关闭；后发FIN包的一方执行的是被动关闭。主动关闭的一方会进入TIME_WAIT状态，并且在此状态停留两倍的MSL时长。（MSL指的是报文段的最大生存时间，如果报文段在网络活动了MSL时间，还没有被接收，那么会被丢弃。关于MSL的大小，RFC 793协议中给出的建议是两分钟，不过实际上不同的操作系统可能有不同的设置，以Linux为例，通常是半分钟，两倍的MSL就是一分钟，也就是60秒，并且这个数值是硬编码在内核中的，也就是说除非你重新编译内核，否则没法修改它）

当某个TCP端点关闭连接时，会在内存中保存一个控制块，记录最近关闭连接的IP和端口号，这个信息只会存在一小段时间，通常是所估计的最大分段使用期的两倍（称为2MSL，通常为2分钟），以确保这段时间内不会创建具有相同地址的和端口号的新连接。

1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，

2）`有足够的时间让这个连接不会跟后面的连接混在一起`（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）


由于现在高速路由的使用，使得重复分组几乎不可能在几分钟内出现。


`tcp_tw_recycle`：顾名思义就是回收TIME_WAIT连接。

当多个客户端通过NAT方式联网并与服务端交互时，服务端看到的是同一个IP，也就是说对服务端而言这些客户端实际上等同于一个，可惜由于这些客户端的时间戳可能存在差异，于是乎从服务端的视角看，便可能出现时间戳错乱的现象，进而直接`导致时间戳小的数据包被丢弃`。


`tcp_tw_reuse`：顾名思义就是复用TIME_WAIT连接。当创建新连接的时候，如果可能的话会考虑复用相应的TIME_WAIT连接。通常认为「tcp_tw_reuse」比「tcp_tw_recycle」安全一些，这是因为一来TIME_WAIT创建时间必须超过一秒才可能会被复用；二来只有连接的时间戳是递增的时候才会被复用。

不过需要注意的是在哪里使用，既然我们要复用连接，那么当然`应该在连接的发起方使用`，而`不能在被连接方使用`。举例来说：客户端向服务端发起HTTP请求，服务端响应后主动关闭连接，于是TIME_WAIT便留在了服务端，此类情况使用「tcp_tw_reuse」是无效的，因为服务端是被连接方，所以不存在复用连接一说。让我们延伸一点来看，比如说服务端是PHP，它查询另一个MySQL服务端，然后主动断开连接，于是TIME_WAIT就落在了PHP一侧，此类情况下使用「tcp_tw_reuse」是有效的，因为此时PHP相对于MySQL而言是客户端，它是连接的发起方，所以可以复用连接。

对于一个client来讲，如果总是疯狂地连接某个IP的同一个端口，并且连接完之后主动关闭连接，会导致大量的time_wait状态的连接，如果系统没有设置 net.ipv4.tcp_tw_reuse = 1 ， 则会导致bind失败（虽然该bind的是隐式的）


SO_REUSEADDR可以用在以下四种情况下。 
常用于服务器端,端口被占用后，不是listen是否能够成功，主要是bind能否成功。

1、`当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时`，而你启动的程序的socket2要占用该地址和端口，你的程序就要用到该选项。 
2、SO_REUSEADDR允许`同一port上启动同一服务器的多个实例`(多个进程)。但`每个实例绑定的IP地址是不能相同的`。在有多块网卡或用IP Alias技术的机器可以测试这种情况。 
3、SO_REUSEADDR允许`单个进程绑定相同的端口到多个socket上`，但每个socket绑定的`ip地址不同`。这和2很相似，区别请看UNPv1。 
4、SO_REUSEADDR允许完全相同的地址和端口的重复绑定。但这只用于UDP的多播，不用于TCP。



####3次握手
对于建链接的3次握手，主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。

这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。

关于建连接时SYN超时。试想一下，如果server端接到了clien发的SYN后回了SYN-ACK后client掉线了，server端没有收到client回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server端如果在一定时间内没有收到的TCP会重发SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。




####4次挥手
对于4次挥手，其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。

为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？
这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。
但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了.
所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

####TCP重传机制
http://coolshell.cn/articles/11564.html

比如，发送端发了1,2,3,4,5一共五份数据，接收端收到了1，2，于是回ack 3，然后收到了4（注意此时3没收到），此时的TCP会怎么办？


1）超时重传机制

不回ack，死等3，当发送方发现收不到3的ack超时后，会重传3。这会导致4和5即便已经收到了，而发送方也完全不知道发生了什么事，因为没有收到Ack，所以，发送方可能会悲观地认为也丢了，所以有可能也会导致4和5的重传。

对此发送方有两种选择：
一种是仅重传timeout的包。也就是第3份数据。
另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。


2）快速重传机制

TCP引入了一种叫Fast Retransmit 的算法，`不以时间驱动，而以数据驱动重传`。也就是说，如果，包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的ack，就重传。Fast Retransmit的好处是不用等timeout了再重传。

![](http://coolshell.cn//wp-content/uploads/2014/05/FASTIncast021.png)

Fast Retransmit只解决了一个问题，就是timeout的问题，它依然面临一个艰难的选择，就是重转之前的一个还是重装所有的问题

3) SACK 方法

Selective Acknowledgment (SACK)（参看RFC 2018），这种方式需要在TCP头里加一个SACK的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版.这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。

![](http://coolshell.cn//wp-content/uploads/2014/05/tcp_sack_example-1024x577.jpg)


这里还需要注意一个问题——接收方Reneging，所谓`Reneging的意思就是接收方有权把已经报给发送端SACK里的数据给丢了`。这样干是不被鼓励的，因为这个事会把问题复杂化了，但是，接收方这么做可能会有些极端情况，比如要把内存给别的更重要的东西。所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out，如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack。

注意：SACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。


4) Duplicate SACK – 重复收到数据的问题
Duplicate SACK又称D-SACK，其主要使用了SACK来告诉发送方有哪些数据被重复接收了。

D-SACK使用了SACK的第一个段来做标志，
如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK
如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK

可见，引入了D-SACK，有这么几个好处：

1）可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。

2）是不是自己的timeout太小了，导致重传。

3）网络上出现了先发的包后到的情况（又称reordering）

4）网络上是不是把我的数据包给复制了。





